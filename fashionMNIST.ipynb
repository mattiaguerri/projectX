{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "74IkMyDtSSbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import standard PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
        "\n",
        "# import torchvision module to handle image manipulation\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# calculate train time, writing train data to files etc.\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "from collections  import OrderedDict\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "torch.set_printoptions(linewidth=120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJNh6icBTp__",
        "colab_type": "text"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZShXdkjSvVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "e731b7ab-1ca9-4de9-b6fe-13eaec88ba2d"
      },
      "source": [
        "# Use standard FashionMNIST dataset\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:07, 3761199.74it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 94553.99it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 4078638.93it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 31349.41it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTePuHqHT7Tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = torch.utils.data.DataLoader(train_set, batch_size = 1)\n",
        "# type(loader.dataset[0][0])  # this is to access one of the images.\n",
        "# type(loader.dataset[0][1])  # this is to access the label."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK7qt6sdZOtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = loader.dataset[10][0]\n",
        "# images.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DccsnbvxWrca",
        "colab_type": "code",
        "outputId": "7f1b3705-048e-421f-a612-b23b2451e606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "images.size()\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "imgplot = plt.imshow(images[0, :, :].numpy())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtHQlLVhVR6U",
        "colab_type": "text"
      },
      "source": [
        "### Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBKxYmlNT9Hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "    # conv 1\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # conv 2\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # fc1\n",
        "    t = t.reshape(-1, 12*4*4)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # fc2\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # output\n",
        "    t = self.out(t)\n",
        "    # don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQDS_UKi53eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
        "\n",
        "    self.conv5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.conv6 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=64*7*7, out_features=128)\n",
        "    self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
        "    self.out = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "  # define forward function\n",
        "  def forward(self, t):\n",
        "\n",
        "    t = F.relu(self.conv1(t))\n",
        "    t = F.relu(self.conv2(t))\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    t = F.relu(self.conv3(t))\n",
        "    t = F.relu(self.conv4(t))\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    t = F.relu(self.conv5(t))\n",
        "    t = F.relu(self.conv6(t))\n",
        "\n",
        "    # fc1\n",
        "    t = t.reshape(-1, t.shape[1]*t.shape[2]*t.shape[3])\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # fc2\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # output\n",
        "    t = self.out(t)\n",
        "    # don't need softmax here since we'll use cross-entropy as activation.\n",
        "\n",
        "    return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHv9GJD4VXMA",
        "colab_type": "code",
        "outputId": "a7e3ff5a-5d82-4863-fee3-b9931b47d938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Network sanity check.\n",
        "x = loader.dataset[0][0]\n",
        "x = x.unsqueeze(0)\n",
        "model = Network()\n",
        "y = model(x)\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFn8ckEG8o7g",
        "colab_type": "code",
        "outputId": "05d8e1dc-e2c4-493b-e195-c8fc37da356a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cuda = torch.device(\"cuda\")\n",
        "\n",
        "modelGPU = Network().to(device=cuda)\n",
        "y = modelGPU(x.to(device=cuda))\n",
        "\n",
        "y.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5-4l9QKixev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store hyperparameters in a dictionary.\n",
        "\n",
        "# params = OrderedDict(\n",
        "#     lr = [.01, .001],\n",
        "#     batch_size = [100, 1000],\n",
        "#     shuffle = [True, False]\n",
        "# )\n",
        "\n",
        "params = OrderedDict(\n",
        "    lr = [.01],\n",
        "    batch_size = [100],\n",
        "    shuffle = [True]\n",
        ")\n",
        "\n",
        "epochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaMps8h8ktpT",
        "colab_type": "text"
      },
      "source": [
        "### RunBuilder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JM8b_WTkvsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
        "# combinations of hyper-parameters\n",
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "\n",
        "    Run = namedtuple('Run', params.keys())\n",
        "\n",
        "    runs = []\n",
        "    for v in product(*params.values()):\n",
        "      runs.append(Run(*v))\n",
        "    \n",
        "    return runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmLBvuLdq7qP",
        "colab_type": "text"
      },
      "source": [
        "### RunManager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vew-87-Iqk2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper class, help track loss, accuracy, epoch time, run time, \n",
        "# hyper-parameters etc. Also record to TensorBoard and write into csv, json.\n",
        "class RunManager():\n",
        "  def __init__(self):\n",
        "\n",
        "    # tracking every epoch count, loss, accuracy, time\n",
        "    self.epoch_count = 0\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "    self.epoch_start_time = None\n",
        "\n",
        "    # tracking every run count, run data, hyper-params used, time\n",
        "    self.run_params = None\n",
        "    self.run_count = 0\n",
        "    self.run_data = []\n",
        "    self.run_start_time = None\n",
        "\n",
        "    # record model, loader and TensorBoard \n",
        "    self.network = None\n",
        "    self.loader = None\n",
        "    self.tb = None\n",
        "\n",
        "  # record the count, hyper-param, model, loader of each run\n",
        "  # record sample images and network graph to TensorBoard  \n",
        "  def begin_run(self, run, network, loader):\n",
        "\n",
        "    self.run_start_time = time.time()\n",
        "\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.loader = loader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    images, labels = next(iter(self.loader))\n",
        "    grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "    self.tb.add_image('images', grid)\n",
        "    self.tb.add_graph(self.network, images.to(device=cuda))\n",
        "\n",
        "  # when run ends, close TensorBoard, zero epoch count\n",
        "  def end_run(self):\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  # zero epoch count, loss, accuracy, \n",
        "  def begin_epoch(self):\n",
        "    self.epoch_start_time = time.time()\n",
        "\n",
        "    self.epoch_count += 1\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "\n",
        "  # \n",
        "  def end_epoch(self):\n",
        "    # calculate epoch duration and run duration(accumulate)\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "\n",
        "    # record epoch loss and accuracy\n",
        "    loss = self.epoch_loss / len(self.loader.dataset)\n",
        "    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
        "\n",
        "    # Record epoch loss and accuracy to TensorBoard \n",
        "    self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
        "\n",
        "    # Record params to TensorBoard\n",
        "    for name, param in self.network.named_parameters():\n",
        "      self.tb.add_histogram(name, param, self.epoch_count)\n",
        "      self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "    \n",
        "    # Write into 'results' (OrderedDict) for all run related data\n",
        "    results = OrderedDict()\n",
        "    results[\"run\"] = self.run_count\n",
        "    results[\"epoch\"] = self.epoch_count\n",
        "    results[\"loss\"] = loss\n",
        "    results[\"accuracy\"] = accuracy\n",
        "    results[\"epoch duration\"] = epoch_duration\n",
        "    results[\"run duration\"] = run_duration\n",
        "\n",
        "    # Record hyper-params into 'results'\n",
        "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "    self.run_data.append(results)\n",
        "    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
        "\n",
        "    # display epoch information and show progress\n",
        "    clear_output(wait=True)\n",
        "    display(df)\n",
        "\n",
        "  # accumulate loss of batch into entire epoch loss\n",
        "  def track_loss(self, loss):\n",
        "    # multiply batch size so variety of batch sizes can be compared\n",
        "    self.epoch_loss += loss.item() * self.loader.batch_size\n",
        "\n",
        "  # accumulate number of corrects of batch into entire epoch num_correct\n",
        "  def track_num_correct(self, preds, labels):\n",
        "    self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _get_num_correct(self, preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "  \n",
        "  # save end results of all runs into csv, json for further analysis\n",
        "  def save(self, fileName):\n",
        "\n",
        "    pd.DataFrame.from_dict(\n",
        "        self.run_data, \n",
        "        orient = 'columns',\n",
        "    ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "      json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPFTgdFatWEr",
        "colab_type": "text"
      },
      "source": [
        "### Training (CPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-8o_cQJtYJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# m = RunManager()\n",
        "\n",
        "# # get all runs from params using RunBuilder class\n",
        "# for run in RunBuilder.get_runs(params):\n",
        "\n",
        "#     # if params changes, following line of code should reflect the changes too\n",
        "#     network = Network()\n",
        "#     loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)\n",
        "#     optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
        "\n",
        "#     m.begin_run(run, network, loader)\n",
        "#     for epoch in range(epochs):\n",
        "      \n",
        "#       m.begin_epoch()\n",
        "#       for batch in loader:\n",
        "        \n",
        "#         images = batch[0]\n",
        "#         labels = batch[1]\n",
        "#         preds = network(images)\n",
        "#         loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         m.track_loss(loss)\n",
        "#         m.track_num_correct(preds, labels)\n",
        "\n",
        "#       m.end_epoch()\n",
        "#     m.end_run()\n",
        "\n",
        "# # when all runs are done, save results to files\n",
        "# m.save('results')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiC76gFpHvhj",
        "colab_type": "text"
      },
      "source": [
        "### Training (GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARU8ni8eHqCx",
        "colab_type": "code",
        "outputId": "fd2825a5-5c89-44e6-aa0b-4923b1abc664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "source": [
        "m = RunManager()\n",
        "\n",
        "# get all runs from params using RunBuilder class\n",
        "for run in RunBuilder.get_runs(params):\n",
        "\n",
        "    # if params changes, following line of code should reflect the changes too\n",
        "    networkGPU = Network().to(device=cuda)\n",
        "    loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)\n",
        "    optimizer = optim.Adam(networkGPU.parameters(), lr=run.lr)\n",
        "\n",
        "    m.begin_run(run, networkGPU, loader)\n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "      m.begin_epoch()\n",
        "      for batch in loader:\n",
        "        \n",
        "        images = batch[0].to(device=cuda)\n",
        "        labels = batch[1]\n",
        "        preds = networkGPU(images)\n",
        "        #print(\"\\n\", \"QQQQQ\", \"\\n\")\n",
        "        preds = preds.cpu()\n",
        "        loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        m.track_loss(loss)\n",
        "        m.track_num_correct(preds, labels)\n",
        "\n",
        "      m.end_epoch()\n",
        "    m.end_run()\n",
        "\n",
        "# when all runs are done, save results to files\n",
        "m.save('results')\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>epoch duration</th>\n",
              "      <th>run duration</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>shuffle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.689463</td>\n",
              "      <td>0.734500</td>\n",
              "      <td>13.694653</td>\n",
              "      <td>13.855547</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.417593</td>\n",
              "      <td>0.844150</td>\n",
              "      <td>13.668971</td>\n",
              "      <td>27.781739</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.375741</td>\n",
              "      <td>0.859583</td>\n",
              "      <td>13.847923</td>\n",
              "      <td>41.898382</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.352348</td>\n",
              "      <td>0.866400</td>\n",
              "      <td>13.740108</td>\n",
              "      <td>55.897347</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.350492</td>\n",
              "      <td>0.869800</td>\n",
              "      <td>13.711618</td>\n",
              "      <td>69.864850</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.344196</td>\n",
              "      <td>0.871150</td>\n",
              "      <td>13.682228</td>\n",
              "      <td>83.808920</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.339486</td>\n",
              "      <td>0.873017</td>\n",
              "      <td>13.711214</td>\n",
              "      <td>97.819330</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.337416</td>\n",
              "      <td>0.874917</td>\n",
              "      <td>13.645008</td>\n",
              "      <td>111.751872</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0.330341</td>\n",
              "      <td>0.877433</td>\n",
              "      <td>13.625719</td>\n",
              "      <td>125.658743</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0.329936</td>\n",
              "      <td>0.876883</td>\n",
              "      <td>13.574610</td>\n",
              "      <td>139.516532</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0.333440</td>\n",
              "      <td>0.876000</td>\n",
              "      <td>13.594727</td>\n",
              "      <td>153.373135</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0.322096</td>\n",
              "      <td>0.879717</td>\n",
              "      <td>13.536490</td>\n",
              "      <td>167.180806</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0.323374</td>\n",
              "      <td>0.878450</td>\n",
              "      <td>13.613364</td>\n",
              "      <td>181.066164</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0.314918</td>\n",
              "      <td>0.882617</td>\n",
              "      <td>13.573507</td>\n",
              "      <td>194.931890</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0.321370</td>\n",
              "      <td>0.879833</td>\n",
              "      <td>13.531239</td>\n",
              "      <td>208.748954</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0.312931</td>\n",
              "      <td>0.882583</td>\n",
              "      <td>13.513873</td>\n",
              "      <td>222.550601</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>0.313166</td>\n",
              "      <td>0.883133</td>\n",
              "      <td>13.667090</td>\n",
              "      <td>236.487909</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0.309646</td>\n",
              "      <td>0.885767</td>\n",
              "      <td>13.609010</td>\n",
              "      <td>250.363503</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0.307008</td>\n",
              "      <td>0.886317</td>\n",
              "      <td>13.494330</td>\n",
              "      <td>264.120220</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.320286</td>\n",
              "      <td>0.881850</td>\n",
              "      <td>13.570085</td>\n",
              "      <td>277.957820</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>0.333474</td>\n",
              "      <td>0.876967</td>\n",
              "      <td>13.557409</td>\n",
              "      <td>291.782332</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>0.308568</td>\n",
              "      <td>0.884733</td>\n",
              "      <td>13.605693</td>\n",
              "      <td>305.659095</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>0.298131</td>\n",
              "      <td>0.890017</td>\n",
              "      <td>13.564953</td>\n",
              "      <td>319.497705</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>0.320775</td>\n",
              "      <td>0.884533</td>\n",
              "      <td>13.557257</td>\n",
              "      <td>333.340856</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0.321547</td>\n",
              "      <td>0.882117</td>\n",
              "      <td>13.574233</td>\n",
              "      <td>347.209179</td>\n",
              "      <td>0.01</td>\n",
              "      <td>100</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    run  epoch      loss  accuracy  ...  run duration    lr  batch_size  shuffle\n",
              "0     1      1  0.689463  0.734500  ...     13.855547  0.01         100     True\n",
              "1     1      2  0.417593  0.844150  ...     27.781739  0.01         100     True\n",
              "2     1      3  0.375741  0.859583  ...     41.898382  0.01         100     True\n",
              "3     1      4  0.352348  0.866400  ...     55.897347  0.01         100     True\n",
              "4     1      5  0.350492  0.869800  ...     69.864850  0.01         100     True\n",
              "5     1      6  0.344196  0.871150  ...     83.808920  0.01         100     True\n",
              "6     1      7  0.339486  0.873017  ...     97.819330  0.01         100     True\n",
              "7     1      8  0.337416  0.874917  ...    111.751872  0.01         100     True\n",
              "8     1      9  0.330341  0.877433  ...    125.658743  0.01         100     True\n",
              "9     1     10  0.329936  0.876883  ...    139.516532  0.01         100     True\n",
              "10    1     11  0.333440  0.876000  ...    153.373135  0.01         100     True\n",
              "11    1     12  0.322096  0.879717  ...    167.180806  0.01         100     True\n",
              "12    1     13  0.323374  0.878450  ...    181.066164  0.01         100     True\n",
              "13    1     14  0.314918  0.882617  ...    194.931890  0.01         100     True\n",
              "14    1     15  0.321370  0.879833  ...    208.748954  0.01         100     True\n",
              "15    1     16  0.312931  0.882583  ...    222.550601  0.01         100     True\n",
              "16    1     17  0.313166  0.883133  ...    236.487909  0.01         100     True\n",
              "17    1     18  0.309646  0.885767  ...    250.363503  0.01         100     True\n",
              "18    1     19  0.307008  0.886317  ...    264.120220  0.01         100     True\n",
              "19    1     20  0.320286  0.881850  ...    277.957820  0.01         100     True\n",
              "20    1     21  0.333474  0.876967  ...    291.782332  0.01         100     True\n",
              "21    1     22  0.308568  0.884733  ...    305.659095  0.01         100     True\n",
              "22    1     23  0.298131  0.890017  ...    319.497705  0.01         100     True\n",
              "23    1     24  0.320775  0.884533  ...    333.340856  0.01         100     True\n",
              "24    1     25  0.321547  0.882117  ...    347.209179  0.01         100     True\n",
              "\n",
              "[25 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL6xeD7h2vjq",
        "colab_type": "text"
      },
      "source": [
        "### TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvTA8sPV1BF3",
        "colab_type": "code",
        "outputId": "d54909e4-4577-4f22-f076-ed8cd724cc80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-23 12:49:53--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.237.203.145, 3.228.157.109, 34.193.139.214, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.237.203.145|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  12%[=>                  ]   1.59M  7.85MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  37.6MB/s    in 0.3s    \n",
            "\n",
            "2019-11-23 12:49:53 (37.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO6yjDiy2pI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = './runs'\n",
        "get_ipython().system_raw(\n",
        "'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        ".format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MwQqpKO21zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqyxZTF225SN",
        "colab_type": "code",
        "outputId": "285fc49e-8f91-4fa1-9104-eae0f3abf6f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://f3b256b1.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47_08E0D29wW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -r runs/Nov*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_jFcChv3Z6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}